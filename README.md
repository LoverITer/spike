

#### 1、Tomcat参数调优

#### 2、分布式Session



#### 3、基于 Guava Cache + Redis  实现分布式二级缓存方案

二级缓存结构：

1、`L1`：一级缓存，内存缓存，Caffeine 和 Guava Cache。

2、`L2`：二级缓存，集中式缓存，支持Redis。

由于大量的缓存读取会导致 L2 的网络成为整个系统的瓶颈，因此 L1 的目标是降低对 L2 的读取次数。避免使用独立缓存系统所带来的网络IO开销问题。

L2 可以避免应用重启后导致的 L1数据丢失的问题，同时无需担心L1会增加太多的内存消耗，因为你可以设置 L1中缓存数据的数量。

**注意**
> 二级缓存在满足高并发的同时也引入了一些新的问题，比如怎么保证分布式场景下各个节点中`本地缓存的一致性问题`，本项目采用`数据变更通知+定期刷新过期缓存`的策略来尽可能的保证缓存的一致性。具体见下文中的 分布式缓存同步 和 分布式缓存一致性保证 两个章节。

**分布式缓存同步**

首先要搞清楚同步的目的：即是为了尽可能保证分布式缓存的一致性。目前支持通过Redis 和 RocketMQ 的发布订阅功能来实现分布式缓存下不同节点本地缓存的同步。当然该项目留好扩展点，可以快速便捷的扩展其他MQ来实现缓存同步。


**缓存更新**

缓存更新包含了对本地 Guava Cache 和 redis的操作，同时会通知其他缓存节点进行缓存更新操作。


#####  3.1 Redis缓存



##### 3.2 本地数据热点缓存

Google Guava Cache 本地热点缓存是一种非常优秀本地缓存解决方案，提供了基于容量，时间和引用的缓存回收方式。基于容量的方式内部实现采用LRU算法，基于引用回收很好的利用了Java虚拟机的垃圾回收机制。其中的缓存构造器CacheBuilder采用构建者模式提供了设置好各种参数的缓存对象，缓存核心类LocalCache里面的内部类Segment与jdk1.7及以前的ConcurrentHashMap非常相似，都继承于ReetrantLock，还有六个队列，以实现丰富的本地缓存方案。


#### 在大型的应用集群中若对Redis访问过度依赖，会否产生应用服务器到Redis之间的网络带宽产生瓶颈？若会产生瓶颈，如何解决这样的问题？

(1)如果nginx服务器内存还算充裕，热点数据估量可以承受的话，可以使用nginx的 lua sharedic来降低redis的依赖

(2)如果单台nginx内存不足，则采用 lvs+keepalived+ n 台nginx服务器对内存进行横向拓展

(3)如果lua sharedic成本过高无法承受，则将redis改造为cluster架构，应用集群只连接到n台slave上来均摊网络带宽消耗，且使redis集群的各主机尽量不处在同一个机房或网段，避免使用同一个出入口导致网络带宽瓶颈